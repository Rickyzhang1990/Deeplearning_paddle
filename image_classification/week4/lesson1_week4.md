## 复习  
归一化和批归一化发生的时刻  
数据输入和批归一化：层与层向下传播时候  
BN的作用：加速训练，防止梯度消失和梯度爆炸，防止过拟合  
随着深度加深，梯度消失导致无法对前面网络的权重进行有效的调整  
为什么resnet可以克服梯度消失问题：把反向传播中的连乘变成连加  
迁移学习：网络结构，预训练参数   
两种做法：model base   finetuning   
使用迁移学习可以躲坑  
## 算法调优    
提供一些指导性的思考  
1、分析目前的问题  
可用数据是什么样（高维数据，图片，音频，预料）  
解决方案属于什么问题  
2、获取数据，分析数据  
尽可能多获得数据   
观察数据的分布  
观察数据的质量，是否含有标签错误   
3、选择模型，模型调优  
确定问题目标   
确定主要的约束条件，求准还是求快，算例，内存如何   
目前已经是最好效果了吗，是否可以进一步提高精度   
4、上线效果   
5、从系统吐出的错误中查找问题  
数据预处理：去掉错误的值（人工标注出错）；人类也无法处理的数据  
数据扩充：数据增强：水平翻转，随机抠图，旋转，色彩抖动    
每个像素减去均值  
数据不均衡的弊端  
不均衡导致泛化能力弱  
应对方式：下采样，类别均衡；使用迁移学习（学习率应该降低。10-4）  
学习率是关键的超参数之一   
结课大作业：[猫的十二分类任务](https://aistudio.baidu.com/aistudio/projectdetail/107627)  
